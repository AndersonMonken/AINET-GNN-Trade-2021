{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch_geometric as tg\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, ChebConv, GATConv\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, GATConv, AGNNConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN, GConvGRU, GConvLSTM\n",
    "from torch_geometric_temporal.data.splitter import discrete_train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'graph_data.pkl'\n",
    "data_in = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('trade_savez_files.npz', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: '.ljust(32), device)\n",
    "#print('Model Name: '.ljust(32), str(model_name.__name__))\n",
    "#print('Model params:{:19} lr: {:.4f}     weight_decay: {:.4f}'.format('',lr, weight_decay))    \n",
    "#print('Total number of epochs to run: '.ljust(32), epochs)\n",
    "print('*' * 65)\n",
    "infeat = 1\n",
    "outfeat = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_torch_data(graph_rawdata):\n",
    "    list_from     = np.array([x[0] for x in graph_rawdata['edges']])\n",
    "    list_to       = np.array([x[1] for x in graph_rawdata['edges']])\n",
    "    list_features = np.array([x[2] for x in graph_rawdata['edges']])\n",
    "\n",
    "    edge_index = torch.tensor([list_from, list_to], dtype = torch.long)\n",
    "    edge_attr = torch.tensor(list_features, dtype = torch.float32)\n",
    "\n",
    "    x = np.array([x['NetWeight'] for x in graph_rawdata['nodes'].values()])[:, np.newaxis]\n",
    "    y = np.array([x['L1_soybean'] for x in graph_rawdata['nodes'].values()])[:, np.newaxis]\n",
    "    node_x = torch.tensor(x, dtype = torch.float32)\n",
    "    node_y = torch.tensor(y, dtype = torch.float32)\n",
    "    torch_data = Data(x = node_x, y = node_y, edge_index = edge_index, edge_attr = edge_attr)\n",
    "    graph_rawdata['torch'] = torch_data.clone().to(device)\n",
    "    return graph_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_data = [make_graph_torch_data(v) for k, v in data_in.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_data[2]['torch'].edge_index.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_data[:-6], temporal_data[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = len(y)\n",
    "# test_size = int(n * 0.2)\n",
    "# train_idx, test_idx = train_test_split(range(n), test_size=test_size, random_state=1651516)\n",
    "# torch_data.train_idx = torch.tensor(train_idx, dtype = torch.long)\n",
    "# torch_data.test_idx = torch.tensor(test_idx, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cheb_net(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(cheb_net, self).__init__()\n",
    "        \n",
    "        self.conv1 = ChebConv(in_channels, 1, K = 5)#, cached=True)\n",
    "        self.linear_out = nn.Linear(1, out_channels)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = 0.2, training=self.training)\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "model = cheb_net(infeat, outfeat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(in_channels, 20, add_self_loops = False)#, cached=True)\n",
    "        self.conv2 = GCNConv(20, 5, add_self_loops = False) #data.num_classes)#, cached=True)\n",
    "        self.conv3 = GCNConv(5, 3, add_self_loops = False)#data.num_classes)#, cached=True)\n",
    "        self.linear_out = nn.Linear(3, out_channels)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = 0.2, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = 0.2, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "model = GCNet(infeat, outfeat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_features, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(node_features, 64, 10)\n",
    "        self.recurrent_2 = GConvGRU(64, 32, 5)\n",
    "        self.recurrent_3 = GConvGRU(32, 16, 5)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.recurrent_3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_features, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(RecurrentGCN_Small, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(node_features, 16,K)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN_Large(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, node_features, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(RecurrentGCN_Large, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(node_features, 16,K)\n",
    "        self.recurrent_2 = GConvGRU(16, 32, K)\n",
    "        self.recurrent_3 = GConvGRU(32, 64, K)\n",
    "        self.recurrent_4 = GConvGRU(64, 32, K)\n",
    "        self.recurrent_5 = GConvGRU(32, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_5(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, out_channels)\n",
    "\n",
    "    def forward(self, x_in, edge_index, edge_weight):\n",
    "        h, c = self.recurrent_1(x_in, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Large(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Large, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 16, K)\n",
    "\n",
    "        self.linear = torch.nn.Linear(16, out_channels)\n",
    "\n",
    "    def forward(self, x_in, edge_index, edge_weight):\n",
    "        h, c = self.recurrent_1(x_in, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_2(h, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_3(h, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_4(h, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x, c = self.recurrent_5(h, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCRNN_Mod(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K):\n",
    "        super(DCRNN_Mod, self).__init__()\n",
    "        self.recurrent_1 =  DCRNN(in_channels, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, out_channels)\n",
    "        self.dropout = dropout\n",
    "    def forward(self, x_in, edge_index, edge_weight):\n",
    "        h = self.recurrent_1(x_in, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        y = self.linear(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout):\n",
    "        super(GCNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = GCNConv(in_channels, 20, add_self_loops = False)#, cached=True)\n",
    "        self.conv2 = GCNConv(20, 5, add_self_loops = False) #data.num_classes)#, cached=True)\n",
    "        self.conv3 = GCNConv(5, 3, add_self_loops = False)#data.num_classes)#, cached=True)\n",
    "        self.linear_out = nn.Linear(3, out_channels)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = self.dropout, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = self.dropout, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.linear_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [5,3,2]\n",
    "dropout = [0.1,0.3,0.5]\n",
    "import itertools\n",
    "model_options = []\n",
    "for element in itertools.product(dropout, K):\n",
    "    model_options.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = [10,1,0.5,0.1]\n",
    "weight_decay = [0.5,0.1]\n",
    "epochs = [100]\n",
    "models = [LSTM_Mod_Small(in_channels = 1, out_channels = 1, K = 5).to(device),\n",
    "          LSTM_Mod_Small(in_channels = 1, out_channels = 1, K = 3).to(device),\n",
    "          LSTM_Mod_Small(in_channels = 1, out_channels = 1, K = 2).to(device),\n",
    "          LSTM_Mod_Large(in_channels = 1, out_channels = 1, K = 5).to(device),\n",
    "          LSTM_Mod_Large(in_channels = 1, out_channels = 1, K = 3).to(device),\n",
    "          LSTM_Mod_Large(in_channels = 1, out_channels = 1, K = 2).to(device),\n",
    "          RecurrentGCN_Small(node_features = 1, K = 5).to(device),\n",
    "          RecurrentGCN_Small(node_features = 1, K = 3).to(device),\n",
    "          RecurrentGCN_Small(node_features = 1, K = 2).to(device),\n",
    "          RecurrentGCN_Large(node_features = 1, K = 5).to(device),\n",
    "          RecurrentGCN_Small(node_features = 1, K = 3).to(device),\n",
    "          RecurrentGCN_Small(node_features = 1, K = 2).to(device),\n",
    "          GCNet(in_channels = 1, out_channels = 1, K = 5).to(device),\n",
    "          GCNet(in_channels = 1, out_channels = 1, K = 3).to(device),\n",
    "          GCNet(in_channels = 1, out_channels = 1, K = 2).to(device)\n",
    "         ]\n",
    "split_location = [-6, -1, -24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "model_options = []\n",
    "for element in itertools.product(models, lr, weight_decay, epochs, split_location):\n",
    "    model_options.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_dataset)\n",
    "random.shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.reverse()\n",
    "test_dataset.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execution(settings):\n",
    "    model, lr, weight_decay, epochs, split_location = settings\n",
    "    print( lr, weight_decay, epochs, split_location)\n",
    "    train_dataset, test_dataset = temporal_data[:split_location], temporal_data[split_location:]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "\n",
    "    train_performance = []\n",
    "    test_performance = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "            cost = cost + torch.mean((y_hat-snapshot['torch'].y)**2)\n",
    "        cost = cost / (time+1)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_performance.append(float(cost))\n",
    "\n",
    "        model.eval()\n",
    "        test_cost = 0\n",
    "        for time, snapshot in enumerate(test_dataset):\n",
    "            y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "            test_cost = test_cost + torch.mean((y_hat-snapshot['torch'].y)**2)\n",
    "        test_cost = test_cost / (time+1)\n",
    "        test_performance.append(float(cost))\n",
    "\n",
    "        if (epoch % int(epochs/5) == 0): \n",
    "            print('Epoch: {}           Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "        if (epoch == epochs - 1):\n",
    "            print('-'*65,'\\nFinal epoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "    print('-'*65)\n",
    "    \n",
    "    return (train_performance, test_performance, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "for i, element in enumerate(model_options):\n",
    "    results = model_execution(element)\n",
    "    model_results[i] = {\n",
    "        'model' : element[0],\n",
    "        'lr' : element[1],\n",
    "        'weight_decay' : element[2],\n",
    "        'epochs' : element[3],\n",
    "        'split_location' : element[4],\n",
    "        'train_loss_trace' : results[0],\n",
    "        'test_loss_trace' : results[1],\n",
    "        'trained_model' : results[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_results,open('model_results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1a =  GConvLSTM(in_channels, 24, K)\n",
    "        self.recurrent_1b =  GConvLSTM(in_channels, 24, K)\n",
    "        self.linear1 = torch.nn.Linear(48,12)\n",
    "        self.linear2 = torch.nn.Linear(12, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                ha, ca = self.recurrent_1a(x_in, edge_index, edge_weight, None, None)\n",
    "                hb, cb = self.recurrent_1b(x_in, edge_index, edge_weight, None, None)\n",
    "            else:\n",
    "                ha, ca = self.recurrent_1a(x_in, edge_index, edge_weight, ha, ca)\n",
    "                hb, cb = self.recurrent_1b(x_in, edge_index, edge_weight, hb, cb)\n",
    "                \n",
    "            xa = F.relu(ha)\n",
    "            xa = F.dropout(xa, p=self.dropout, training=self.training)\n",
    "            xb = F.relu(hb)\n",
    "            xb = F.dropout(xb, p=self.dropout, training=self.training)\n",
    "            x = self.linear1(torch.cat((xa,xb),1))\n",
    "            #x = self.linear1(torch.cat((x,x_in),1))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear2(x)\n",
    "            if i == 0 :\n",
    "                x_out = x\n",
    "            else:\n",
    "                x_out = torch.cat((x_out, x),1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Medium(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1a =  GConvLSTM(in_channels, 24, K)\n",
    "        self.recurrent_1b =  GConvLSTM(in_channels, 24, K)\n",
    "        self.linear1 = torch.nn.Linear(48,12)\n",
    "        self.linear2 = torch.nn.Linear(12, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                ha, ca = self.recurrent_1a(x_in, edge_index, edge_weight, None, None)\n",
    "                hb, cb = self.recurrent_1b(x_in, edge_index, edge_weight, None, None)\n",
    "            else:\n",
    "                ha, ca = self.recurrent_1a(x_in, edge_index, edge_weight, ha, ca)\n",
    "                hb, cb = self.recurrent_1b(x_in, edge_index, edge_weight, hb, cb)\n",
    "                \n",
    "            xa = F.relu(ha)\n",
    "            xa = F.dropout(xa, p=self.dropout, training=self.training)\n",
    "            xb = F.relu(hb)\n",
    "            xb = F.dropout(xb, p=self.dropout, training=self.training)\n",
    "            x = self.linear1(torch.cat((xa,xb),1))\n",
    "            #x = self.linear1(torch.cat((x,x_in),1))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear2(x)\n",
    "            if i == 0 :\n",
    "                x_out = x\n",
    "            else:\n",
    "                x_out = torch.cat((x_out, x),1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1a =  GConvLSTM(in_channels, 24, K)\n",
    "        self.recurrent_1b =  GConvLSTM(in_channels, 24, K)\n",
    "        self.linear1 = torch.nn.Linear(48,12)\n",
    "        self.linear2 = torch.nn.Linear(12, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                h, c = self.recurrent_1a(x_in, edge_index, edge_weight, None, None)\n",
    "\n",
    "            else:\n",
    "                h, c = self.recurrent_1a(x_in, edge_index, edge_weight, h, c)\n",
    "                \n",
    "            x = F.relu(h)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            #x = self.linear1(torch.cat((x,x_in),1))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear2(x)\n",
    "            if i == 0 :\n",
    "                x_out = x\n",
    "            else:\n",
    "                x_out = torch.cat((x_out, x),1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 128, K)\n",
    "        self.linear = torch.nn.Linear(128, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                h, c = self.recurrent_1(x_in, edge_index, edge_weight, None, None)\n",
    "\n",
    "            else:\n",
    "                h, c = self.recurrent_1(x_in, edge_index, edge_weight, h, c)\n",
    "                \n",
    "            x = F.relu(h)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear(x)\n",
    "            if i == 0 :\n",
    "                x_out = x\n",
    "            else:\n",
    "                x_out = torch.cat((x_out, x),1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(RecurrentGCN_Small, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(in_channels, 16,1)\n",
    "        self.recurrent_2 = GConvGRU(16, 32,2)\n",
    "        self.recurrent_3 = GConvGRU(32, 16,3)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                h = self.recurrent_1(x_in, edge_index, edge_weight, None)\n",
    "            else:\n",
    "                h = self.recurrent_1(x_in, edge_index, edge_weight, h)\n",
    "            x = F.relu(h)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear(x)\n",
    "            if i == 0 :\n",
    "                x_out = x\n",
    "            else:\n",
    "                x_out = torch.cat((x_out, x),1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, snapshot in enumerate(train_dataset):\n",
    "    if i == 0:\n",
    "        y_out = snapshot['torch'].y\n",
    "    else:\n",
    "        y_out = torch.cat((y_out, snapshot['torch'].y),1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = LSTM_Mod_Small(in_channels = 1,out_channels = 1, K = 3, dropout = 0.15).to(device)\n",
    "\n",
    "for i, snapshot in enumerate(test_dataset):\n",
    "    if i == 0:\n",
    "        y_test = snapshot['torch'].y\n",
    "    else:\n",
    "        y_test = torch.cat((y_test, snapshot['torch'].y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.08, weight_decay = 0.01)\n",
    "epochs = 500\n",
    "train_performance = []\n",
    "test_performance = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    cost = 0\n",
    "    y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset])\n",
    "    cost = torch.sqrt(torch.mean((y_hat - y_out)**2))\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    train_performance.append(cost)\n",
    "    \n",
    "    model.eval()\n",
    "    test_cost = 0\n",
    "    size_test = len(test_dataset)\n",
    "    y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset + test_dataset])\n",
    "    y_hat = y_hat[:,-size_test:]\n",
    "    test_cost = torch.sqrt(torch.mean((y_hat - y_test)**2))\n",
    "    test_performance.append(test_cost)\n",
    "    \n",
    "    if (epoch % int(epochs/100) == 0): \n",
    "        print('Epoch: {}           Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "    if (epoch == epochs - 1):\n",
    "        print('-'*65,'\\nFinal epoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "print('-'*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_performance)\n",
    "plt.plot(train_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = {\n",
    "        'model' : model,\n",
    "        'train_loss_trace' : train_performance,\n",
    "        'test_loss_trace' : test_performance,\n",
    "        'trained_model' : model.state_dict(),\n",
    "    }\n",
    "import pickle\n",
    "pickle.dump(model_save,open('model_lstm_recurrent.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'test_rmse' : [x.detach().numpy() for x in test_performance], 'train_rmse' : [x.detach().numpy() for x in train_performance]}).reset_index().rename(columns = {'index' : 'epoch'})\n",
    "\n",
    "df.to_csv('model_train_performance-gc-lstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_perf = []\n",
    "model.eval()\n",
    "y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset])\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "    last_prediction = y_hat[:,time].cpu().detach().numpy()\n",
    "    for i, val in enumerate(last_prediction):\n",
    "        #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'train-predict'})\n",
    "y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset + test_dataset])\n",
    "\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "    last_prediction = y_hat[:,time + len(train_dataset)].cpu().detach().numpy()\n",
    "    for i, val in enumerate(last_prediction):\n",
    "        #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'test-predict'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_perf = pd.DataFrame(list_perf)\n",
    "df_perf[df_perf['country'] == 'USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df_perf.to_csv('model_prediction-s-gc-lstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_perf, x = 'date', y = 'val', color = 'country')\n",
    "fig.write_html('plot4.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot['period'] in period_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "reporter = 'China'\n",
    "partner = 'United States of America'\n",
    "period_list = [201901,201902,201903,201904,201905,201906,201907,201908,201909,201910,201911,201912]\n",
    "\n",
    "mod_dataset = {}\n",
    "for time, snapshot in enumerate(data_in.values()):\n",
    "    if time == 0:\n",
    "        reporter_num = [k for k,v in snapshot['country_dict'].items() if v == reporter][0]\n",
    "        partner_num = [k for k,v in snapshot['country_dict'].items() if v == partner][0]\n",
    "    snapshot_mod = copy.deepcopy(snapshot)\n",
    "    if snapshot['period'] in period_list:\n",
    "        snapshot_mod['edges'] = [x for x in snapshot_mod['edges'] if not (x[0] == partner_num and x[1] == reporter_num)]\n",
    "        snapshot_mod['edges'] = [x for x in snapshot_mod['edges'] if not (x[0] == reporter_num and x[1] == partner_num)]\n",
    "        if len(snapshot_mod['edges']) != len(snapshot['edges']):\n",
    "            print('dropped edge',snapshot['period'])\n",
    "        print('mod period',snapshot['period'])\n",
    "    mod_dataset[time] = snapshot_mod\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = [make_graph_torch_data(v) for k, v in mod_dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_perf = []\n",
    "model.eval()\n",
    "y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in alt_data])\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    if snapshot['period'] in period_list:\n",
    "        y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "        last_prediction = y_hat[:,time].cpu().detach().numpy()\n",
    "        for i, val in enumerate(last_prediction):\n",
    "            #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'alt-predict'})\n",
    "            \n",
    "y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in temporal_data])\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    if snapshot['period'] in period_list:\n",
    "        y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "        last_prediction = y_hat[:,time].cpu().detach().numpy()\n",
    "        for i, val in enumerate(last_prediction):\n",
    "            #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'base-predict'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt = pd.DataFrame(list_perf)\n",
    "df_alt.to_csv('model_prediction_scenario.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout):\n",
    "        self.dropout = dropout\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 64, K)\n",
    "        self.linear = torch.nn.Linear(64, out_channels)\n",
    "\n",
    "    def forward(self, snapshot_list):\n",
    "        for i, snapshot in enumerate(snapshot_list):\n",
    "            x_in, edge_index, edge_weight = snapshot\n",
    "            if i == 0:\n",
    "                h, c = self.recurrent_1(x_in, edge_index, edge_weight, None, None)\n",
    "            else:\n",
    "                h, c = self.recurrent_1(x_in, edge_index, edge_weight, h, c)\n",
    "            x = F.sigmoid(h)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = LSTM_Mod_Small(in_channels = 1,out_channels = 1, K = 3, dropout = 0.1).to(device)\n",
    "\n",
    "for i, snapshot in enumerate(test_dataset):\n",
    "    if i == 0:\n",
    "        y_test = snapshot['torch'].y\n",
    "    else:\n",
    "        y_test = torch.cat((y_test, snapshot['torch'].y),1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.08, weight_decay = 0.01)\n",
    "epochs = 100\n",
    "train_performance = []\n",
    "test_performance = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset[:time+1]])\n",
    "        cost = cost + torch.sqrt(torch.mean((y_hat - snapshot['torch'].y)**2))\n",
    "        #print(time)\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    train_performance.append(cost)\n",
    "    \n",
    "    model.eval()\n",
    "    test_cost = 0\n",
    "    size_test = len(test_dataset)\n",
    "    for time, snapshot in enumerate(test_dataset):\n",
    "        y_hat = model([[snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr] for snapshot in train_dataset + test_dataset[:time+1]])\n",
    "        test_cost = test_cost + torch.sqrt(torch.mean((y_hat - snapshot['torch'].y)**2))\n",
    "        #print(time)\n",
    "    test_cost = test_cost / (time+1)\n",
    "    test_performance.append(test_cost)\n",
    "    \n",
    "    if (epoch % int(epochs/100) == 0): \n",
    "        print('Epoch: {}           Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "    if (epoch == epochs - 1):\n",
    "        print('-'*65,'\\nFinal epoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "print('-'*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat[:,-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, snapshot in enumerate(test_dataset):\n",
    "    if i == 0:\n",
    "        y_out = snapshot['torch'].y\n",
    "    else:\n",
    "        y_out = torch.cat((y_out, snapshot['torch'].y),1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf = pd.DataFrame(list_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "train_losses = []\n",
    "accs = []\n",
    "model.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.mse_loss(out[data.train_idx], data.y[data.train_idx])\n",
    "    train_losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    pred = model(data)\n",
    "    RMSE  = RMSELoss(pred[data.test_idx], data.y[data.test_idx])\n",
    "    \n",
    "    accs.append(RMSE)\n",
    "    if (epoch % int(epochs/10) == 0): \n",
    "        print('Epoch: {}           Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, loss, RMSE))\n",
    "    if (epoch == epochs):\n",
    "        print('-'*65,'\\nFinal epoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, loss, RMSE))\n",
    "print('-'*65)\n",
    "print('\\033[1mBest Accuracy\\nEpoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}\\n'\n",
    "      .format(accs.index(min(accs))+1, train_losses[accs.index(min(accs))], min(accs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
