{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch_geometric as tg\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, ChebConv, GATConv\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE, GATConv, AGNNConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN, GConvGRU, GConvLSTM\n",
    "from torch_geometric_temporal.data.splitter import discrete_train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'graph_data.pkl'\n",
    "data_in = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('trade_savez_files.npz', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: '.ljust(32), device)\n",
    "#print('Model Name: '.ljust(32), str(model_name.__name__))\n",
    "#print('Model params:{:19} lr: {:.4f}     weight_decay: {:.4f}'.format('',lr, weight_decay))    \n",
    "#print('Total number of epochs to run: '.ljust(32), epochs)\n",
    "print('*' * 65)\n",
    "infeat = 1\n",
    "outfeat = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph_torch_data(graph_rawdata):\n",
    "    list_from     = np.array([x[0] for x in graph_rawdata['edges']])\n",
    "    list_to       = np.array([x[1] for x in graph_rawdata['edges']])\n",
    "    list_features = np.array([x[2] for x in graph_rawdata['edges']])\n",
    "\n",
    "    edge_index = torch.tensor([list_from, list_to], dtype = torch.long)\n",
    "    edge_attr = torch.tensor(list_features, dtype = torch.float32)\n",
    "\n",
    "    x = np.array([x['NetWeight'] for x in graph_rawdata['nodes'].values()])[:, np.newaxis]\n",
    "    y = np.array([x['L1_soybean'] for x in graph_rawdata['nodes'].values()])[:, np.newaxis]\n",
    "    node_x = torch.tensor(x, dtype = torch.float32)\n",
    "    node_y = torch.tensor(y, dtype = torch.float32)\n",
    "    torch_data = Data(x = node_x, y = node_y, edge_index = edge_index, edge_attr = edge_attr)\n",
    "    graph_rawdata['torch'] = torch_data.clone().to(device)\n",
    "    return graph_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_data = [make_graph_torch_data(v) for k, v in data_in.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_data[2]['torch'].edge_index.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(in_channels, 20, add_self_loops = False)#, cached=True)\n",
    "        self.conv2 = GCNConv(20, 5, add_self_loops = False) #data.num_classes)#, cached=True)\n",
    "        self.conv3 = GCNConv(5, 3, add_self_loops = False)#data.num_classes)#, cached=True)\n",
    "        self.linear_out = nn.Linear(3, out_channels)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = 0.2, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, p = 0.2, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.linear_out(x)\n",
    "        return x\n",
    "model = GCNet(infeat, outfeat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout, act_f):\n",
    "        self.dropout = dropout\n",
    "        self.act_f = act_f\n",
    "        super(RecurrentGCN_Small, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(in_channels, 16,K)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN_Large(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout, act_f):\n",
    "        self.dropout = dropout\n",
    "        self.act_f = act_f\n",
    "        super(RecurrentGCN_Large, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(in_channels, 16,K)\n",
    "        self.recurrent_2 = GConvGRU(16, 32, K)\n",
    "        self.recurrent_3 = GConvGRU(32, 64, K)\n",
    "        self.recurrent_4 = GConvGRU(64, 32, K)\n",
    "        self.recurrent_5 = GConvGRU(32, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_3(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_4(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.recurrent_5(x, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Small(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, dropout, act_f):\n",
    "        self.dropout = dropout\n",
    "        self.act_f = act_f\n",
    "        super(LSTM_Mod_Small, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, out_channels)\n",
    "\n",
    "    def forward(self, x_in, edge_index, edge_weight):\n",
    "        h, c = self.recurrent_1(x_in, edge_index, edge_weight)\n",
    "        h = self.act_f(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x = self.linear(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mod_Large(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, K, act_f, dropout):\n",
    "        self.dropout = dropout\n",
    "        self.act_f = act_f\n",
    "        super(LSTM_Mod_Large, self).__init__()\n",
    "        self.recurrent_1 =  GConvLSTM(in_channels, 16, K)\n",
    "        self.recurrent_2 =  GConvLSTM(16, 32, K)\n",
    "        self.recurrent_3 =  GConvLSTM(32, 64, K)\n",
    "        self.recurrent_4 =  GConvLSTM(64, 32, K)\n",
    "        self.recurrent_5 =  GConvLSTM(32, 16, K)\n",
    "        self.linear = torch.nn.Linear(16, out_channels)\n",
    "\n",
    "    def forward(self, x_in, edge_index, edge_weight):\n",
    "        h, c = self.recurrent_1(x_in, edge_index, edge_weight)\n",
    "        h = self.act_f(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_2(h, edge_index, edge_weight)\n",
    "        h = self.act_f(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_3(h, edge_index, edge_weight)\n",
    "        h = self.act_f(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h, c = self.recurrent_4(h, edge_index, edge_weight)\n",
    "        h = self.act_f(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        x, c = self.recurrent_5(h, edge_index, edge_weight)\n",
    "        x = self.act_f(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [3, 5]\n",
    "dropout = [0.1, 0, 0.25, 0.5]\n",
    "activation_functions = [F.tanh, F.relu, F.leaky_relu, F.sigmoid]\n",
    "lr = [0.1, 0.01, 1]\n",
    "weight_decay = [0, 0.05] #0.05\n",
    "epochs = [100]\n",
    "split_location = [-6,-24,-1]\n",
    "import itertools\n",
    "model_options = []\n",
    "for element in itertools.product(dropout, K, activation_functions, lr, weight_decay, epochs, split_location):\n",
    "    model_options.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_options = [({'dropout' : v[0], 'K' : v[1], 'act_f' : v[2]},\n",
    "                        {'lr' : v[3], 'weight_decay' : v[4], 'epochs' : v[5], 'split_location' : v[6]}) for v in model_options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exec_options = []\n",
    "for model_param_i in model_param_options:\n",
    "    for model in [LSTM_Mod_Large, RecurrentGCN_Small, LSTM_Mod_Small, , RecurrentGCN_Large]:\n",
    "        model_exec_options.append((model(in_channels = 1, out_channels = 1, **model_param_i[0]).to(device),model_param_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execution(settings):\n",
    "    model = settings[0]\n",
    "    lr, weight_decay, epochs, split_location = settings[1][1].values()\n",
    "    print(model)\n",
    "    print(settings[1][0])\n",
    "    print( lr, weight_decay, epochs, split_location)\n",
    "    model_params = settings[1][0]\n",
    "\n",
    "    train_dataset, test_dataset = temporal_data[:split_location], temporal_data[split_location:]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "\n",
    "    train_performance = []\n",
    "    test_performance = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        cost = 0\n",
    "        for time, snapshot in enumerate(train_dataset):\n",
    "            y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "            cost = cost + torch.mean((y_hat - snapshot['torch'].y)**2)\n",
    "        cost = torch.sqrt(cost / (time+1))\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_performance.append(float(cost))\n",
    "        \n",
    "        test_cost = 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for time, snapshot in enumerate(test_dataset):\n",
    "            y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "            test_cost = test_cost + torch.mean((y_hat - snapshot['torch'].y)**2)\n",
    "        test_cost = torch.sqrt(test_cost / (time+1))\n",
    "        test_performance.append(float(test_cost))\n",
    "\n",
    "        if (epoch % int(epochs/10) == 0): \n",
    "            print('Epoch: {}           Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "        if (epoch == epochs - 1):\n",
    "            print('-'*65,'\\nFinal epoch: {}     Train loss: {:.4f}   Test RMSE: {:.4f}'.format(epoch, cost, test_cost))\n",
    "    print('-'*65)\n",
    "    print(y_hat)\n",
    "    return (train_performance, test_performance, model, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "for i, element in enumerate(model_exec_options):\n",
    "    results = model_execution(element)\n",
    "    model_results[i] = {\n",
    "        'model' : element[0],\n",
    "        'lr' : element[1][1]['lr'],\n",
    "        'weight_decay' : element[1][1]['weight_decay'],\n",
    "        'epochs' : element[1][1]['epochs'],\n",
    "        'split_location' : element[1][1]['split_location'],\n",
    "        'train_loss_trace' : results[0],\n",
    "        'test_loss_trace' : results[1],\n",
    "        'model_obj' : results[2],\n",
    "        'trained_model' : results[2].state_dict(),\n",
    "        'model_params' : results[3]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting model = model_results[0]['model_obj']\n",
    "plt.plot(model_results[0]['test_loss_trace'])\n",
    "plt.plot(model_results[0]['train_loss_trace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first item in list is the best model\n",
    "for i in [0]:\n",
    "    df = pd.DataFrame({'test_rmse' : [x for x in model_results[i]['test_loss_trace']], 'train_rmse' : [x for x in model_results[i]['train_loss_trace']]}).reset_index().rename(columns = {'index' : 'epoch'})\n",
    "    print(i, df.test_rmse.min(), model_results[i]['model_params'], model_results[i]['lr'], model_results[i]['weight_decay'], model_results[i]['split_location'])\n",
    "df.to_csv('model_train_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "model = model_results[i]['model_obj']\n",
    "train_dataset, test_dataset = temporal_data[: model_results[i]['split_location']], temporal_data[ model_results[i]['split_location']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_perf = []\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "    y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "    last_prediction = y_hat.cpu().detach().numpy()\n",
    "    for i, val in enumerate(last_prediction):\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i][0], 'type' : 'train-predict'})\n",
    "for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "    y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "    last_prediction = y_hat.cpu().detach().numpy()\n",
    "    for i, val in enumerate(last_prediction):\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "        list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i][0], 'type' : 'test-predict'})\n",
    "df_perf = pd.DataFrame(list_perf)\n",
    "df_perf.to_csv('model_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "reporter = 'China'\n",
    "partner = 'United States of America'\n",
    "period_list = [201901,201902,201903,201904,201905,201906,201907,201908,201909,201910,201911,201912]\n",
    "\n",
    "mod_dataset = {}\n",
    "for time, snapshot in enumerate(data_in.values()):\n",
    "    if time == 0:\n",
    "        reporter_num = [k for k,v in snapshot['country_dict'].items() if v == reporter][0]\n",
    "        partner_num = [k for k,v in snapshot['country_dict'].items() if v == partner][0]\n",
    "    snapshot_mod = copy.deepcopy(snapshot)\n",
    "    if snapshot['period'] in period_list:\n",
    "        snapshot_mod['edges'] = [x for x in snapshot_mod['edges'] if not (x[0] == partner_num and x[1] == reporter_num)]\n",
    "        snapshot_mod['edges'] = [x for x in snapshot_mod['edges'] if not (x[0] == reporter_num and x[1] == partner_num)]\n",
    "        if len(snapshot_mod['edges']) != len(snapshot['edges']):\n",
    "            print('dropped edge',snapshot['period'])\n",
    "        print('mod period',snapshot['period'])\n",
    "    mod_dataset[time] = snapshot_mod\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = [make_graph_torch_data(v) for k, v in mod_dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_perf = []\n",
    "model.eval()\n",
    "\n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "    if snapshot['period'] in period_list:\n",
    "        y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "        last_prediction = y_hat.cpu().detach().numpy()\n",
    "        for i, val in enumerate(last_prediction):\n",
    "            #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'alt-predict'})\n",
    "            \n",
    "for time, snapshot in enumerate(train_dataset):\n",
    "    y_hat = model(snapshot['torch'].x, snapshot['torch'].edge_index, snapshot['torch'].edge_attr)\n",
    "    if snapshot['period'] in period_list:\n",
    "        y = snapshot['torch'].y.cpu().detach().numpy()\n",
    "        last_prediction = y_hat[:,time].cpu().detach().numpy()\n",
    "        for i, val in enumerate(last_prediction):\n",
    "            #print(f\"Country: {snapshot['country_dict'][i]}, Period: {snapshot['period']}, Actual: {y[i][0]}, Predicted: {last_prediction[i]}\")\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : y[i][0], 'type' : 'actual'})\n",
    "            list_perf.append({'country' : snapshot['country_dict'][i], 'date' : snapshot['date'], 'val' : last_prediction[i], 'type' : 'base-predict'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt = pd.DataFrame(list_perf)\n",
    "df_alt.to_csv('model_prediction_scenario.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
